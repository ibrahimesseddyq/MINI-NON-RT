+ use  Whitted s algorithm for lightning



Vec3f castRay(const Vec3f &orig, const Vec3f &dir, ..., uint32_t depth)
{
    if (depth > options.maxDepth)
        return options.backgroundColor;

    float tNear = INFINITY;  //distance to the intersected object
    Object *hitObject = NULL;  //pointer to the intersected object
    Vec3f hitColor = 0;  //the color of the intersected point
    if (trace(orig, dir, objects, tnear, hitObject....) {
        switch (hitObject->materialType) {
            case REFLECTION_AND_REFRACTION:
                // compute reflection and refraction ray
                ...
                // cast reflection and refraction ray, don't forget to increment depth
                Vec3f reflectionColor = castRay(hitPoint, reflectionDirection, ..., depth + 1);
                Vec3f refractionColor = castRay(hitPoint, refractionDirection, ..., depth + 1);
                float kr;  //how much light is reflected, computed by the Fresnel equation
                fresnel(dir, N, hitObject->ior, kr);
                hitColor = reflectionColor * kr + refractionColor * (1 - kr);
                break; 
            case REFLECTION:
                // compute reflection ray
                ...
                // cast reflection ray, increment depth
                Vec3f reflectionColor = castRay(hitPoint, reflectionDirection, ..., depth + 1);
                hitColor = reflectionColor;
                break;
            default:
                // compute Phong illumination model
                for (uint32_t i = 0; i < lights.size(); ++i) {
                    // compute shadow ray
                    Vec3f lightDirection = lights[i].position - hitPoint;
                    float len2 = dot(lightDirection, lightDirection);  //length^2
                    float tNearShadow = INFINITY;
                    // is hitPoint in the shadow of this light and is the intersection point close to the light itself?
                    bool isInShadow = (trace(hitPoint, normalize(lightDirection), tNearShadow, ...) && tNearShadow * tNearShadow < len2);
                    // compute the Phong model terms
                    hitColor = (1 - isInShadow) * (...);
                }
                break;
        }
    }

    return hitColor;
} 

bool trace(const Vec3f &orig, const Vec3f &dir, float tNear, ...)
{ 
    hitObject = NULL;
    for (uint32_t i = 0; i < objects.size(); ++i) {
        float tNearK = INFINITY;
        if (objects[i]->intersect(orig, dir, tNearK, ...) && tNearK < tNear) {
            hitObject = objects[i];
            tNear = tNearK;
            ...
        }
    }

    return (hitObject != NULL);
}


//comera configuration

float imageAspectRatio = imageWidth / (float)imageHeight; // assuming width > height
float Px = (2 * ((x + 0.5) / imageWidth) - 1) * tan(fov / 2 * M_PI / 180) * imageAspectRatio;
float Py = (1 - 2 * ((y + 0.5) / imageHeight) * tan(fov / 2 * M_PI / 180);
Vec3f rayOrigin(0);
Vec3f rayDirection = Vec3f(Px, Py, -1) - rayOrigin; // note that this just equal to Vec3f(Px, Py, -1);
rayDirection = normalize(rayDirection); // it's a direction so don't forget to normalize

//Note how the camera coordinate system moves with the camera. Our pseudo code can easily be modified to account for camera transformation (rotation and translation, scaling a camera are not particularly recommended):

float imageAspectRatio = imageWidth / imageHeight; // assuming width > height
float Px = (2 * ((x + 0.5) / imageWidth) - 1) * tan(fov / 2 * M_PI / 180) * imageAspectRatio;
float Py = (1 - 2 * ((y + 0.5) / imageHeight) * tan(fov / 2 * M_PI / 180);
Vec3f rayOrigin = Point3(0, 0, 0);
Matrix44f cameraToWorld;
cameraToWorld.set(...); // set matrix
Vec3f rayOriginWorld, rayPWorld;
cameraToWorld.multVectMatrix(rayOrigin, rayOriginWorld);
cameraToWorld.multVectMatrix(Vec3f(Px, Py, -1), rayPWorld);
Vec3f rayDirection = rayPWorld - rayOriginWorld;
rayDirection.normalize(); // it's a direction so don't forget to normalize
